{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4527,
     "status": "ok",
     "timestamp": 1748240847772,
     "user": {
      "displayName": "허세민",
      "userId": "14816006501778571850"
     },
     "user_tz": -540
    },
    "id": "D9545gHkt9f4",
    "outputId": "8a7877b6-9405-4a50-9508-2d752d98c7b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fvcore\n",
      "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/cysong/miniconda3/envs/capstone/lib/python3.9/site-packages (from fvcore) (1.26.4)\n",
      "Collecting yacs>=0.1.6 (from fvcore)\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/cysong/miniconda3/envs/capstone/lib/python3.9/site-packages (from fvcore) (6.0.2)\n",
      "Requirement already satisfied: tqdm in /home/cysong/miniconda3/envs/capstone/lib/python3.9/site-packages (from fvcore) (4.67.1)\n",
      "Collecting termcolor>=1.1 (from fvcore)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: Pillow in /home/cysong/miniconda3/envs/capstone/lib/python3.9/site-packages (from fvcore) (10.2.0)\n",
      "Collecting tabulate (from fvcore)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting iopath>=0.1.7 (from fvcore)\n",
      "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions in /home/cysong/miniconda3/envs/capstone/lib/python3.9/site-packages (from iopath>=0.1.7->fvcore) (4.12.2)\n",
      "Collecting portalocker (from iopath>=0.1.7->fvcore)\n",
      "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
      "Building wheels for collected packages: fvcore, iopath\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61443 sha256=b095a73daa309a24299305a486b8f4a5d18944a49e1d6530fc571f34db7366a1\n",
      "  Stored in directory: /home/cysong/.cache/pip/wheels/83/42/02/66178d16e5c44dc26d309931834956baeda371956e86fbd876\n",
      "  Building wheel for iopath (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31570 sha256=52aa4bb8be1192ae751b418bcb72c9513157dcb3735cb18a53360eb766ebfb6e\n",
      "  Stored in directory: /home/cysong/.cache/pip/wheels/c1/13/6d/441d8f2af76ee6d2a3e67eebb1d0c556fefcee0a8b32266a8e\n",
      "Successfully built fvcore iopath\n",
      "Installing collected packages: yacs, termcolor, tabulate, portalocker, iopath, fvcore\n",
      "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-3.1.1 tabulate-0.9.0 termcolor-3.1.0 yacs-0.1.8\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install fvcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3308,
     "status": "ok",
     "timestamp": 1748240851101,
     "user": {
      "displayName": "허세민",
      "userId": "14816006501778571850"
     },
     "user_tz": -540
    },
    "id": "OjmCs-sOt-uT",
    "outputId": "b966f56a-b163-4fa3-ca7f-0a533c889d3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting av\n",
      "  Downloading av-14.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
      "Downloading av-14.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: av\n",
      "Successfully installed av-14.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7266,
     "status": "ok",
     "timestamp": 1748223001253,
     "user": {
      "displayName": "허세민",
      "userId": "14816006501778571850"
     },
     "user_tz": -540
    },
    "id": "GymqalBZuAMu",
    "outputId": "8447e149-a953-4c52-8867-a697a65cd05c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/cysong/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.getLogger(\"pytorchvideo\").setLevel(logging.CRITICAL)\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# X3D 모델 로드\n",
    "model_name = 'x3d_s'\n",
    "model = torch.hub.load('facebookresearch/pytorchvideo', model_name, pretrained=True)\n",
    "device = \"cuda:0\"\n",
    "feature_model = model.eval().to(device)\n",
    "del feature_model.blocks[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1748223001263,
     "user": {
      "displayName": "허세민",
      "userId": "14816006501778571850"
     },
     "user_tz": -540
    },
    "id": "S_mDzNgsuVI2"
   },
   "outputs": [],
   "source": [
    "def load_deweather_model(device):\n",
    "    from .model.ESDNet import ESDNet\n",
    "    deweather_model = ESDNet(\n",
    "        en_feature_num=48,\n",
    "        en_inter_num=32,\n",
    "        de_feature_num=64,\n",
    "        de_inter_num=32,\n",
    "        sam_number=1\n",
    "    ).to(device)\n",
    "\n",
    "    load_path = 'weight/deweathering_model.pth'\n",
    "    try:\n",
    "        ckpt = torch.load(load_path, map_location=device)\n",
    "        state_dict = ckpt if load_path.endswith('.pth') else ckpt['state_dict']\n",
    "        deweather_model.load_state_dict(state_dict)\n",
    "        print(\"Deweathering model loaded from\", load_path)\n",
    "    except Exception as e:\n",
    "        print(\"Deweathering model checkpoint 로드 실패:\", e)\n",
    "    deweather_model.eval()\n",
    "    return deweather_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 215,
     "status": "ok",
     "timestamp": 1748223001479,
     "user": {
      "displayName": "허세민",
      "userId": "14816006501778571850"
     },
     "user_tz": -540
    },
    "id": "KhyXqiDkuV8O",
    "outputId": "d3c54ff9-c634-4038-b3eb-728c0ed4b304"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m deweather_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_deweather_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m, in \u001b[0;36mload_deweather_model\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_deweather_model\u001b[39m(device):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mESDNet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ESDNet\n\u001b[1;32m      3\u001b[0m     deweather_model \u001b[38;5;241m=\u001b[39m ESDNet(\n\u001b[1;32m      4\u001b[0m         en_feature_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m48\u001b[39m,\n\u001b[1;32m      5\u001b[0m         en_inter_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m         sam_number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      9\u001b[0m     )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m     load_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight/deweathering_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "deweather_model = load_deweather_model(device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68954,
     "status": "ok",
     "timestamp": 1748222962713,
     "user": {
      "displayName": "허세민",
      "userId": "14816006501778571850"
     },
     "user_tz": -540
    },
    "id": "Mhq8A0oivRiX",
    "outputId": "9ef84176-dbc1-4ff1-a34e-b1fce1e3ad26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting performer_pytorch\n",
      "  Downloading performer_pytorch-1.1.4-py3-none-any.whl.metadata (763 bytes)\n",
      "Requirement already satisfied: einops>=0.3 in /usr/local/lib/python3.11/dist-packages (from performer_pytorch) (0.8.1)\n",
      "Collecting local-attention>=1.1.1 (from performer_pytorch)\n",
      "  Downloading local_attention-1.11.1-py3-none-any.whl.metadata (907 bytes)\n",
      "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.11/dist-packages (from performer_pytorch) (2.6.0+cu124)\n",
      "Collecting axial-positional-embedding>=0.1.0 (from performer_pytorch)\n",
      "  Downloading axial_positional_embedding-0.3.12-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting hyper-connections>=0.1.8 (from local-attention>=1.1.1->performer_pytorch)\n",
      "  Downloading hyper_connections-0.1.15-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->performer_pytorch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->performer_pytorch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->performer_pytorch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->performer_pytorch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->performer_pytorch) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.6->performer_pytorch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.6->performer_pytorch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.6->performer_pytorch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.6->performer_pytorch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.6->performer_pytorch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.6->performer_pytorch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.6->performer_pytorch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.6->performer_pytorch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.6->performer_pytorch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->performer_pytorch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->performer_pytorch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->performer_pytorch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.6->performer_pytorch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->performer_pytorch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->performer_pytorch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6->performer_pytorch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6->performer_pytorch) (3.0.2)\n",
      "Downloading performer_pytorch-1.1.4-py3-none-any.whl (13 kB)\n",
      "Downloading axial_positional_embedding-0.3.12-py3-none-any.whl (6.7 kB)\n",
      "Downloading local_attention-1.11.1-py3-none-any.whl (9.4 kB)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m115.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hyper_connections-0.1.15-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, hyper-connections, axial-positional-embedding, local-attention, performer_pytorch\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed axial-positional-embedding-0.3.12 hyper-connections-0.1.15 local-attention-1.11.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 performer_pytorch-1.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install performer_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1748223003460,
     "user": {
      "displayName": "허세민",
      "userId": "14816006501778571850"
     },
     "user_tz": -540
    },
    "id": "3MBQGZ5GvPS3",
    "outputId": "4097cbf7-1bba-424a-bdb2-b2259b55ad03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (stages): ModuleList(\n",
       "    (0): ConvBlock(\n",
       "      (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (conv): DECOUPLED(\n",
       "        (norm2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm1d): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2d): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16)\n",
       "        (conv1d): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), groups=16)\n",
       "      )\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.2, inplace=False)\n",
       "        (3): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (4): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (2): AttnBlock(\n",
       "      (performer): Performer(\n",
       "        (net): SequentialSequence(\n",
       "          (layers): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): PreLayerNorm(\n",
       "                (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): SelfAttention(\n",
       "                  (fast_attention): FastAttention(\n",
       "                    (kernel_fn): ReLU()\n",
       "                  )\n",
       "                  (local_attn): LocalAttention(\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    (rel_pos): SinusoidalEmbeddings()\n",
       "                  )\n",
       "                  (to_q): Linear(in_features=32, out_features=32, bias=True)\n",
       "                  (to_k): Linear(in_features=32, out_features=32, bias=True)\n",
       "                  (to_v): Linear(in_features=32, out_features=32, bias=True)\n",
       "                  (to_out): Linear(in_features=32, out_features=32, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (1): PreLayerNorm(\n",
       "                (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Chunk(\n",
       "                  (fn): FeedForward(\n",
       "                    (w1): Linear(in_features=32, out_features=32, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (dropout): Dropout(p=0.2, inplace=False)\n",
       "                    (w2): Linear(in_features=32, out_features=32, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (proj_updater): ProjectionUpdater(\n",
       "          (instance): SequentialSequence(\n",
       "            (layers): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): PreLayerNorm(\n",
       "                  (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): SelfAttention(\n",
       "                    (fast_attention): FastAttention(\n",
       "                      (kernel_fn): ReLU()\n",
       "                    )\n",
       "                    (local_attn): LocalAttention(\n",
       "                      (dropout): Dropout(p=0.1, inplace=False)\n",
       "                      (rel_pos): SinusoidalEmbeddings()\n",
       "                    )\n",
       "                    (to_q): Linear(in_features=32, out_features=32, bias=True)\n",
       "                    (to_k): Linear(in_features=32, out_features=32, bias=True)\n",
       "                    (to_v): Linear(in_features=32, out_features=32, bias=True)\n",
       "                    (to_out): Linear(in_features=32, out_features=32, bias=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (1): PreLayerNorm(\n",
       "                  (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Chunk(\n",
       "                    (fn): FeedForward(\n",
       "                      (w1): Linear(in_features=32, out_features=32, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (dropout): Dropout(p=0.2, inplace=False)\n",
       "                      (w2): Linear(in_features=32, out_features=32, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "  (linear): Linear(in_features=192, out_features=32, bias=True)\n",
       "  (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (drop_out): Dropout(p=0.2, inplace=False)\n",
       "  (pooling): AdaptiveMaxPool3d(output_size=(1, 1, 1))\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from .model.classifier import Model\n",
    "\n",
    "classifier = Model(ff_mult=1, dims=(32, 32), depths=(1, 1))\n",
    "ckpt_path = \"weight/De_final_model.pth\"\n",
    "classifier.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1sag2CQ7JLhanIJyvh5ynhgaxBzpZHKgd"
    },
    "executionInfo": {
     "elapsed": 12441,
     "status": "ok",
     "timestamp": 1748224716186,
     "user": {
      "displayName": "허세민",
      "userId": "14816006501778571850"
     },
     "user_tz": -540
    },
    "id": "uCLLI7iruegk",
    "outputId": "17568153-2b88-448f-d0fd-03a8e83c7d99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.transforms import ToTensor, Normalize, Resize, Compose\n",
    "from collections import deque\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "# ======================\n",
    "# 설정\n",
    "# ======================\n",
    "CLIP_LEN = 13\n",
    "IMG_SIZE = 160\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "MEAN = [0.45, 0.45, 0.45]\n",
    "STD = [0.225, 0.225, 0.225]\n",
    "MAX_FRAMES = 200\n",
    "ANOMALY_THRESHOLD = 0.60\n",
    "ALERT_FRAMES = 20\n",
    "\n",
    "# ======================\n",
    "# 전처리 정의\n",
    "# ======================\n",
    "transform_frame = Compose([\n",
    "    Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    ToTensor()\n",
    "])\n",
    "normalize = Normalize(mean=MEAN, std=STD)\n",
    "frame_buffer = deque(maxlen=CLIP_LEN)\n",
    "anomaly_streak = 0  # 연속 이상 프레임 수\n",
    "\n",
    "# ======================\n",
    "# 비디오 캡처\n",
    "# ======================\n",
    "cap = cv2.VideoCapture(\"/mnt/d/Capstone/data/UCF_snowsynth/Videos/Fighting/Fighting007_x264.mp4\")\n",
    "assert cap.isOpened(), \"❌ 카메라 또는 영상 열기 실패\"\n",
    "\n",
    "frame_count = 0\n",
    "start_time = time.time()\n",
    "\n",
    "while frame_count < MAX_FRAMES:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"📉 영상 종료 또는 오류\")\n",
    "        break\n",
    "\n",
    "    # 1. OpenCV → PIL → Tensor\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_pil = Image.fromarray(frame_rgb)\n",
    "    frame_tensor = transform_frame(frame_pil).unsqueeze(0).to(DEVICE)  # [1, 3, H, W]\n",
    "\n",
    "    # 2. Deweathering\n",
    "    with torch.no_grad():\n",
    "        output, _, _ = deweather_model(frame_tensor)\n",
    "        clean_frame = output[0] if isinstance(output, tuple) else output  # [1, 3, H, W]\n",
    "\n",
    "    # 3. clean_frame: 시각화를 위한 변환\n",
    "    clean_img_np = clean_frame.squeeze(0).detach().cpu().numpy()  # [3, H, W]\n",
    "    clean_img_np = np.transpose(clean_img_np, (1, 2, 0))  # [H, W, C]\n",
    "    clean_img_np = np.clip(clean_img_np * 255.0, 0, 255).astype(np.uint8)  # RGB\n",
    "    clean_img_bgr = cv2.cvtColor(clean_img_np, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # 4. 버퍼에 추가\n",
    "    frame_buffer.append(clean_frame.squeeze(0))  # [3, H, W]\n",
    "\n",
    "    # 5. 클립이 모이면 처리\n",
    "    label = \"Collecting...\"\n",
    "    anomaly_score = None\n",
    "    if len(frame_buffer) == CLIP_LEN:\n",
    "        clip_tensor = torch.stack(list(frame_buffer), dim=0).permute(1, 0, 2, 3)  # [3, T, H, W]\n",
    "        normalized_clip = torch.stack([\n",
    "            normalize(clip_tensor[:, t, :, :]) for t in range(CLIP_LEN)\n",
    "        ], dim=1)  # [3, T, H, W]\n",
    "        clip_tensor = normalized_clip.unsqueeze(0).to(DEVICE)  # [1, 3, T, H, W]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            feat = feature_model(clip_tensor)\n",
    "            pred, _ = classifier(feat)\n",
    "            anomaly_score = torch.sigmoid(pred).item()\n",
    "            label = f\"A: {anomaly_score:.2f}\"\n",
    "\n",
    "        # 이상 상태 연속 체크\n",
    "        if anomaly_score >= ANOMALY_THRESHOLD:\n",
    "            anomaly_streak += 1\n",
    "        else:\n",
    "            anomaly_streak = 0\n",
    "\n",
    "    # 6. FPS 계산\n",
    "    elapsed = time.time() - start_time\n",
    "    fps = frame_count / elapsed if elapsed > 0 else 0\n",
    "    fps_label = f\"FPS: {fps:.2f}\"\n",
    "\n",
    "    # 7. 텍스트 표시 (좌측 상단)\n",
    "    text_position = (10, 20)\n",
    "    cv2.putText(clean_img_bgr, fps_label + \" | \" + label, text_position,\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 255), 1)\n",
    "\n",
    "\n",
    "    # 8. 테두리 추가 조건\n",
    "    if anomaly_streak >= ALERT_FRAMES:\n",
    "        h, w = clean_img_bgr.shape[:2]\n",
    "        cv2.rectangle(clean_img_bgr, (0, 0), (w - 1, h - 1), (0, 0, 255), 3)\n",
    "\n",
    "    # 9. 출력\n",
    "    cv2.imshow(clean_img_bgr)\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "print(\"✅ 처리 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HvnjQniwF8Bb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOdA64KuJdG1hJMuo6xT1d1",
   "gpuType": "T4",
   "machine_shape": "hm",
   "mount_file_id": "1nQhpeb4VQfLOfh7mYVSbK7AKULNnNYYJ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
